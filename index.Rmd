---
title: "Portfolio by Thomas Hubert"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
date: "2024-02-21"
---

### Introduction

Welcome to my Portfolio! This is where I will display my findings during the course 'Computational Musicology' at the UvA.Feel free to look around and ask me any questions :)

In this Corpus I am comparing FIlm Music and Classical Music, and seeing how they interact and how they differ.


-Info-
Thomas Hubert
SNUM: 14642271
Email: thomas.hubert@student.uva.nl

### Visuals

#### Similar Energy Levels Between Classical & Film Music

In the graph below you can see an analysis of the energy levels when comparing two playlists of classical music and of film music. You can see that there indeed appears to be a very similar distribution of energy levels across both genres, you may also be able to see that they similarly have a lot of tracks considered "low" in energy and relatively little considered "high" in energy.

```{r}
library(tidyverse)
library(tidymodels)
library(spotifyr)
library(ggdendro)
library(heatmaply)
library(compmus)

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit |> 
    collect_predictions() |> 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit |> 
    conf_mat_resampled() |> 
    group_by(Prediction) |> mutate(precision = Freq / sum(Freq)) |> 
    group_by(Truth) |> mutate(recall = Freq / sum(Freq)) |> 
    ungroup() |> filter(Prediction == Truth) |> 
    select(class = Prediction, precision, recall)
}  
```

```{r}
ClassicalMusic <- get_playlist_audio_features("", "27Zm1P410dPfedsdoO9fqm")
FilmMusic <- get_playlist_audio_features("", "3FUHkTsK7xNOqrHOXVHRF4")

awards <-
  bind_rows(
    ClassicalMusic |> mutate(category = "Classical Music"),
    FilmMusic |> mutate(category = "Film Music")
  )

awards |>
  ggplot(aes(x = energy)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(~category)

```

#### Comparing Hans Zimmer - Time & Wolfgang Amadeus Mozart - Eine kleine Nachtmusik K.525

In the following two graphs I compare the very famous movie theme 'Time' by Hans Zimmer from the movie Inception, against the classical music piece Eine Kleine Nachtmusik (K.525) by Wolfgang Amadeus Mozart. Both of these pieces are in the key of G-major, but you can clearly see a difference in their song structure. Both pieces are around ~5 minutes in length, but whereas Zimmer tends to hold the listener in a state of harmonic suspense (Many of the notes are repeated over and over), Mozart displays are more classical from of song structure by clearly switching between chords (note the clear distinction of notes in the graph)

```{r}
library(tidyverse)
library(spotifyr)
library(compmus)

#Drawing A Graph For Hans Zimmer
zimmer <-
  get_tidy_audio_analysis("6ZFbXIJkuI1dVNWvzJzown") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

zimmer |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

```{r}

#Drawing A Graph For Mozart
mozart <-
  get_tidy_audio_analysis("4KLVPRo0f6XUJa4t4dnRW6") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

mozart |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

```

#### Comparing Song Sections

Here we can see again how Hans Zimmer doesn't really have a clearly defined song structure, whereas Mozart does seem to do this. Eventhough they use the same musical key.

Hans Zimmer
```{r}

bztH <-
  get_tidy_audio_analysis("6ZFbXIJkuI1dVNWvzJzown") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

bztH |>
  compmus_self_similarity(timbre, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

```


Mozart
```{r}

bztM <-
  get_tidy_audio_analysis("4KLVPRo0f6XUJa4t4dnRW6") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

bztM |>
  compmus_self_similarity(timbre, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

```

#### Chords analysis

Now we will compare the chords used in these two songs.By doing this we can again correlate our findings from the previous two graphs. It appears that while Hans Zimmer's Time and Mozart's Nachtmusik share the same tonic chord (G-Major), and they both certainly make extensive use of thi chord, Zimmer doesn't follow common song structure nearly as much as Mozart does. This could be explained by the strong sense of "norm" back in Mozart's time, but it could also be an effect of more Chordal Thinking in Mozart's time.

```{r}

circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

HansZimZim <-
  get_tidy_audio_analysis("6ZFbXIJkuI1dVNWvzJzown") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

AmadeusMozMoz <-
  get_tidy_audio_analysis("4KLVPRo0f6XUJa4t4dnRW6") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

```


##### Hans Zimmer - Time
```{r}
HansZimZim |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```


##### Mozart - Nachtmusik
```{r}
AmadeusMozMoz |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```


#### Tempo Analysis (Week 11)
Below I will once again compare the two pieces mentioned above, but this time analyzing they tempo's and percieved changes in these tempi.

Hans Zimmer - Time

Given that this is a more recent piece of music, we can see that it generally follows a more stable tempo around ~125 bpm, but we can also see that the analysis is having a hard time with all the drones and swells in this production.
```{r}
ZimmerTempo <- get_tidy_audio_analysis("6ZFbXIJkuI1dVNWvzJzown")

ZimmerTempo |>
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()

```

Mozart - Nachtmusik

The line in Mozart's piece seems to be a more well defined that that in Zimmer's, but we can also so it increasing and decreasing over time. This doesn't seem to happen section by section, but rather in a fluid motion. This could be explained that musical tempo in this time was more susceptible to "feeling". Often tempo was given in terms like adagio or presto, rather than a strict musical bpm. So the performance is likely speeding up and slowing down to give weight to certain parts of the song.
```{r}
MozartTempo <- get_tidy_audio_analysis("4KLVPRo0f6XUJa4t4dnRW6")

MozartTempo |>
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()

```


#### Week 12 Clustering
```{r}
ClassicalMusic2 <-
  get_playlist_audio_features("FilmMusic", "37i9dQZF1DX1tz6EDao8it") |>
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

ClassicalMusic2_juice <-
  recipe(
    track.name ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = ClassicalMusic2
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  # step_range(all_predictors()) |> 
  prep(ClassicalMusic2 |> mutate(track.name = str_trunc(track.name, 20))) |>
  juice() |>
  column_to_rownames("track.name")
```

Drawing a graph of Film Music Cluster Analysis

Not entirely sure if this is usefull for the overall analysis, but ok.
```{r}
ClassicalMusic2_dist <- dist(ClassicalMusic2_juice, method = "euclidean")

ClassicalMusic2_dist |> 
  hclust(method = "single") |> # Try single, average, and complete.
  dendro_data() |>
  ggdendrogram()

```

***
Data sourced from SPOTIFY URI.

### Conclusion

This page will list my conclusions. As I am currently still in the exploratory stage of this program, I do not have any definite conclusions yet.
