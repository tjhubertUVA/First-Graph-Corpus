---
title: "Computational Musicology Portfolio by Thomas Hubert"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
date: "Feb-Mar 2024"
---

### Introduction
#### Introduction
Dear Reader,

In this portfolio I will be analyzing a Corpus of two playlists;
'Iconic Soundtracks' by Spotify (37i9dQZF1DX1tz6EDao8it) (82 songs), and
'Top Classical Music on Spotify' by Rogerio Tutti (2shU0q1gKzX4dwpYkLFrPw) (94 songs).

My aim in comparing these two playlist is to uncovering possible similarities between Classical Music and Film Music.
Seeing as a link can be drawn between Classical orchestral pieces that were for example played during an Opera, and
Cinematic orchestral pieces being played during a film. Seeing as both aim to amplify and support the story that is
being told to the audience.

This analysis will be done using various functions of Spotify's own API. My findings will be displayed in a number of
graphs and accompanying texts. First I will display some playlist-level analyses, and then compare two musical pieces against each other for a more in depth analysis. Finally I will present some of the conclusions that can be
drawn from this project.

I hope you find these analyses and conclusions to be of some value in your own musicological research!

Kind regards,
Thomas Hubert

-Info-
Name: Thomas Hubert
SNUM: 14642271
Email: thomas.hubert@student.uva.nl
Date: February & March 2024
Course: Computational Musicology (115215146Y)

```{r}
#Loading Libraries and Defining Functions.
library(tidyverse)
library(tidymodels)
library(spotifyr)
library(ggdendro)
library(heatmaply)
library(compmus)

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit |> 
    collect_predictions() |> 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit |> 
    conf_mat_resampled() |> 
    group_by(Prediction) |> mutate(precision = Freq / sum(Freq)) |> 
    group_by(Truth) |> mutate(recall = Freq / sum(Freq)) |> 
    ungroup() |> filter(Prediction == Truth) |> 
    select(class = Prediction, precision, recall)
}  
```

### Playlist-Level Analysis
#### Playlist-Level Analysis
On this page I will conduct some analyses on a playlist level. Meaning that the following graphs portray patterns that can \n 
be found in one or both of the chosen playlists within the corpus. I will compare some of Spotify's own API markers such as; \n energy, valence, and loudness.\n

#### Characteristic-Analysis
In the graphs below you can see an analysis of the energy, valence and loudness levels when comparing two playlists of classical music and of film music. You can see that there indeed appears to be a very similar distribution of energy levels across both genres, you may also be able to see that they similarly have a lot of tracks considered "low" in energy and relatively little considered "high" in energy. Interesting to note that there are a lot more songs in the Classical Playlist that are considered to be near "0" in energy. It is also interesting to note that these correlations also seem to extend into the valence graph. With almost all graphs considered to be <0,5 value. Loudness also seems to corroborate, but of note is the one massive outlier of "6" in the Classical Playlist. Although this could just be a case of the software over-reading a value in a song.

```{r}
ClassicalMusic <- get_playlist_audio_features("", "2shU0q1gKzX4dwpYkLFrPw")
FilmMusic <- get_playlist_audio_features("", "37i9dQZF1DX1tz6EDao8it")

awards <-
  bind_rows(
    ClassicalMusic |> mutate(category = "Classical Music"),
    FilmMusic |> mutate(category = "Film Music")
  )
```

Valence
```{r}
awards |>
  ggplot(aes(x = valence)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(~category)

```

Loudness
```{r}
awards |>
  ggplot(aes(x = loudness)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(~category)

```

Energy
```{r}
awards |>
  ggplot(aes(x = energy)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(~category)

```

### Comparing Hans Zimmer & Wolfgang Amadeus Mozart
#### Comparing Hans Zimmer & Wolfgang Amadeus Mozart
On this page I would like to compare the first of my pairs of songs from both playlists. Starting off we have two \n
German speaking composers both being consider one of the Greats of their generation. Hans Zimmer is a multi-award \n
winning Film Composer, and Wolfgang Amadeus Mozart barely needs an introduction. \n

In this comparison I will compare Zimmer's 'Time' from the Movie 'Inception' to \n
Mozart's 'Eine kleine Nachtmusik (K.525)'. These two pieces of music were chosen \n
because they are originally written in the same key of G-major, and are both forms \n
of instrumental music.\n

#### Pitch Class-Analysis
As I already mentioned, both of these pieces are in the key of G-major, but you can clearly see a difference in their \n
song structure. Both pieces are around ~5 minutes in length, but whereas Zimmer tends to hold the listener in a state \n
of harmonic suspense (Many of the notes are repeated over and over), Mozart displays are more classical from of song \n
structure by clearly switching between chords (note the clear distinction of notes in the graph). 'Time' is also \n
known for it's use of pedal-tones, which are notes that are held for a very long time during a piece of music. These \n
can also be seen in the graph.\n

Hans Zimmer - Time \n
```{r}
#Drawing A Graph of Hans Zimmer - Time
zimmer <-
  get_tidy_audio_analysis("6ZFbXIJkuI1dVNWvzJzown") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

zimmer |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

Wolfgang Amadeus Mozart - Eine kleine Nachtmusik (K.525) \n
```{r}
#Drawing A Graph of Mozart -  Nachtmusik
mozart <-
  get_tidy_audio_analysis("4KLVPRo0f6XUJa4t4dnRW6") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

mozart |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

```

#### Self Similarity-Analysis
The following two graphs are Self Similarity Matrices, which compares a moment in the song to itself. \n
With this we can see that Zimmer’s ‘Time’ doesn’t really have a clearly defined structure \n
(we would expect a Checkerboard Pattern), but rather it builds and builds. Mozart’s ‘Nachtmusik’ does \n
appear to follow a certain structure, given that we can see a Checkerboard Pattern. To be specific, \n
the structure that Mozart follows in this song is called a Sonata-Rondo form. \n

Hans Zimmer - Time \n
```{r}

bztH <-
  get_tidy_audio_analysis("6ZFbXIJkuI1dVNWvzJzown") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

bztH |>
  compmus_self_similarity(timbre, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

```

Wolfgang Amadeus Mozart - Eine kleine Nachtmusik (K.525) \n
```{r}

bztM <-
  get_tidy_audio_analysis("4KLVPRo0f6XUJa4t4dnRW6") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

bztM |>
  compmus_self_similarity(timbre, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

```

#### Chord-Analysis
Now we will compare the chords used in these two songs. By doing this we can again correlate our \n
findings from the previous two graphs. It appears that while Hans Zimmer’s Time and Mozart’s Nachtmusik \n
share the same tonic chord (G-Major), this doesn’t clearly show up on the graphs. This could be because \n
both songs aren’t exactly tuned to A-440Hz. One observation that might support this is that the Major \n
Chords one semi-tone above and below G (Ab & Gb) do appear to show up in the song. This could be the \n
software trying to compensate for the detuning. We can also correlate our previous statement about song \n
structure, namely that we can observe the previously mentioned Sonata-Rondo form in Mozart’s music, \n
and we can see that Zimmer’s piece is essentially one long build up, with a climax near the end. \n
One reason that Mozart might adhere so strictly to form is the strong sense of “norm” back in Mozart’s \n
time, but it could also be an effect of more Chordal Thinking in Mozart’s time.\n

```{r}
#Preparing the Database
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

HansZimZim <-
  get_tidy_audio_analysis("6ZFbXIJkuI1dVNWvzJzown") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

AmadeusMozMoz <-
  get_tidy_audio_analysis("4KLVPRo0f6XUJa4t4dnRW6") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

```


Hans Zimmer - Time \n
```{r}
#Drawing a Chordogram of Hans Zimmer - Time
HansZimZim |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```


Wolfgang Amadeus Mozart - Eine kleine Nachtmusik (K.525) \n
```{r}
#Drawing a Chordogram of Mozart - Nachtmusik
AmadeusMozMoz |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

#### Tempo-Analysis
Below I will once again compare the two pieces mentioned above, but this time analyzing their \n
tempo’s and perceived changes in these tempi. Given that Hans Zimmer’s ‘Time’ is a more recent \n
piece of music, we can see that it generally follows a more stable tempo around ~125 BPM, but \n
we can also see that the analysis is having a hard time with all the drones and swells in this \n
production. Compare that to the line in Mozart’s piece, which seems to be more well defined that \n
that in Zimmer’s, but we can also so it increasing and decreasing over time. This doesn’t seem \n
to happen section by section, but rather in a fluid motion. This could be explained that musical \n
tempo in this time was more susceptible to “feeling”. Often tempo was given in terms like adagio \n
or presto, rather than a strict musical BPM. So the performance is likely speeding up and slowing \n
down to give weight to certain parts of the song.\n

Hans Zimmer - Time \n
```{r}
ZimmerTempo <- get_tidy_audio_analysis("6ZFbXIJkuI1dVNWvzJzown")

ZimmerTempo |>
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()

```

Wolfgang Amadeus Mozart - Eine kleine Nachtmusik (K.525) \n
```{r}
MozartTempo <- get_tidy_audio_analysis("4KLVPRo0f6XUJa4t4dnRW6")

MozartTempo |>
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()

```

***
Data sourced from SPOTIFY API.

### Conclusions
#### Conclusions
This page will list my conclusions. As I am currently still in the exploratory stage of this program, I do not have any definite conclusions yet.
